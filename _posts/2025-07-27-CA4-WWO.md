---
layout: post
title: "Core Area 4: Communication - Working With Others"
author: "Eric Martin"
date: 2025-07-27
categories: documentation
image: DSGbw.jpg
---
<p style="font-size: 1.75em; font-weight: bold; text-align: center;">
<em>“The effects of technology do not occur at the level of opinions or concepts, but alter sense ratios or patterns of perception steadily and without any resistance.” </em>
</p>

<p style="text-align: right; font-size: 1.25em;">
<em>— Marshall McLuhan</em>
</p>



## Core Area 4: Working With Others

***Core Area 4 Case i: Facilitating Cross-Disciplinary Collaboration in The Alan Turing Institute and British Geological Survey Data Study Groups***

The Data Study Group (DSG) is a flagship educational initiative run by The Alan Turing Institute, the UK’s national institute for data science and AI. Delivered as an intensive, collaborative forum, it brings together early-career researchers, doctoral students, and data scientists to tackle real-world problems posed by external partners. The programme complements the Institute’s doctoral and postdoctoral training and fellowship initiatives. While solutions are developed under time constraints, the broader aim is educational: to train future data scientists through applied, interdisciplinary problem-solving in an open, team-based setting.

As a facilitator for The Alan Turing Institute’s Data Study Group in September 2024 and again in January 2025, I mentor and lead interdisciplinary teams of early-career researchers working on rapid prototyping for applied environmental problems, including geospatial classification, seismic interpretation, and resource characterisation. These mentorship experiences, spanning academic, vocational, and interdisciplinary contexts, helped to develop and inform my approach to teaching, supervision, and programme leadership.

The September 2024 project, <a href="https://www.turing.ac.uk/news/publications/data-study-group-final-report-british-geological-survey" target="_blank" style="text-decoration: underline; color: #004080;"> (Evidence 1) Identifying Potential for Carbon Capture and Storage (CCS) in Rock</a>, delivered in person through the Alan Turing Institute’s Data Study Group in partnership with the BGS, developed a modular machine learning pipeline for automated analysis of petrographic thin-section images, supporting early-stage CCS and hydrogen storage site selection. The team explored porosity estimation using pixel-level colour filtering, grain segmentation via watershed algorithms, and mineral classification with both feature-based random forests and U-Net convolutional networks. As facilitator, I contributed to project design, research direction, codebase development, and implementation strategy. I mentored and worked closely with postgraduate and postdoctoral researchers from across the UK and Europe, supporting technical decisions, bridging disciplinary gaps, guiding technical communication, and maintaining focus during an intensive, collaborative sprint. The challenge addressed a national need for scalable and reproducible assessment of archived geological samples, with over 500,000 thin sections at BGS alone, moving beyond manual and subjective workflows.

>-(Evidence 2) Thank you, everyone, for making the week so enjoyable. It was great getting to know you all; I have learnt loads. Particular thanks to @Eric Martin and @Kathryn Leeming for running the show! 

The January 2025 project,  <a href="https://www.turing.ac.uk/news/publications/data-study-group-final-report-british-geological-survey-0" target="_blank" style="text-decoration: underline; color: #004080;"> (Evidence 3) Detecting Shallow Gas from Marine Seismic Images</a>, also in partnership with the British Geological Survey (BGS), was delivered online over a two-week period. It focused on automating the interpretation of legacy seismic scan data for shallow gas detection. The challenge addressed the digitisation and analysis of kilometres of deteriorated paper records using structure-preserving image enhancement, OCR-based shotpoint detection, and multi-stage deep learning pipelines for feature segmentation. The overarching objective was to use modern technological tools to extract actionable insights and improve the interpretation of a sizable legacy dataset. I served as co-facilitator, leading the design of the image enhancement pipeline, supporting the object detection architecture, and contributing to the theoretical framework and report delivery. I worked alongside postgraduate and postdoctoral researchers across institutions and time zones, supporting both the technical direction and collaborative team coordination. A follow-on phase is currently under consideration to integrate the OCR and segmentation modules into a deployable national screening tool for shallow gas hazard mitigation.

The BGS Head of AI and Informatics, Andrew Kingdon, responded to the finished product:

>-(Evidence 4) This was a really important challenge, a real problem that needs managing as UK develops ever more offshore wind. Really excellent work which highlighted lots of routes forward which British Geological Survey are discussing with our stakeholders.

I am currently serving as Principal Investigator (PI) for the September 2025 Data Study Group challenge in partnership with Cefas (Centre for Environment, Fisheries and Aquaculture Science), focusing on scalable machine learning approaches for detecting oil spills from sunken shipwrecks using satellite Synthetic Aperture Radar (SAR) time series. The dataset includes over fifty SAR snapshots per site, labelled ground truth rasters, wind speed data, and spatial coordinates for known wreck locations. This combination of sequential imagery and environmental covariates presents a rare opportunity to examine time-aware modelling techniques for detecting persistent or emergent oil slicks in noisy, dynamic marine environments. 

In collaboration with Cefas, the project will scope research directions that prioritise interpretability, environmental relevance, and sprint-scale feasibility. Early exploration may focus on adapting time-series models such as ConvLSTM and temporal transformers for multi-frame segmentation, conditioning predictions on environmental factors like wind speed and direction. Lightweight architectures such as ENet or BiSeNet could also be tested for their suitability in operational or resource-constrained settings, particularly where real-time or regional-scale deployment is of interest. Methods that incorporate prior knowledge, such as source proximity or recurrence thresholds may offer further avenues for exploration, alongside domain adaptation strategies to improve cross-sensor robustness.

This challenge presents a technically open problem with strong environmental relevance and supports multiple entry points for methodological innovation. My role as PI includes pre-sprint coordination with Cefas, collaborative scoping of research questions, technical framing, participant support, and ensuring the clarity and rigour of the final outputs. The study group will lay the groundwork for potential follow-on collaborations focused on regional monitoring, national-scale screening tools, or integration into marine hazard detection frameworks.

***Core Area 4: Evidence***

<a href="https://www.linkedin.com/feed/update/urn:li:activity:7303380325538140161/" target="_blank" style="text-decoration: underline; color: #004080;">-(Evidence 5) Event Post: Data Study Group: British Geological Survey – Identifying Potential for Carbon Capture and Storage in Rock </a>

<a href="https://www.linkedin.com/feed/update/urn:li:activity:7303380325538140161/" target="_blank" style="text-decoration: underline; color: #004080;">-(Evidence 6) Publication Post: Data Study Group Final Report: British Geological Survey – Identifying Potential for Carbon Capture and Storage in Rock </a>

<a href="https://www.linkedin.com/posts/activity-7343559396783767553-cCL4?utm_source=share&utm_medium=member_desktop&rcm=ACoAAB2gWhUBp1FrfhHLZDg2LBREtoNsIUe2dWE/" target="_blank" style="text-decoration: underline; color: #004080;">-(Evidence 7) Publication Post: Data Study Group Final Report – British Geological Survey: Detecting Shallow Gas from Marine Seismic Images</a>

<a href="https://www.linkedin.com/feed/update/urn:li:activity:7241088463863734274/?updateEntityUrn=urn%3Ali%3Afs_feedUpdate%3A%28V2%2Curn%3Ali%3Aactivity%3A7241088463863734274%29/" target="_blank" style="text-decoration: underline; color: #004080;">-(Evidence 8) Event Post: Data Study Group: Data Study Group – British Geological Survey: Detecting Shallow Gas from Marine Seismic Images</a>

<a href="/assets/img/TuringEC2.pdf" target="_blank" style="text-decoration: underline; color: #004080;">-(Evidence 9) Alan Turing Institute Employment Confirmation</a>

***Core Area 4 Case ii: GitHub Repositories and Open Knowledge: Supporting Technical Collaboration in Higher Education***

I have worked extensively with students and colleagues on collaborative, code-based teaching and supervision. At the BSc level, I introduce students to noisy, seasonal time-series datasets and support their use of statistical methods including Mann–Kendall trend analysis, Sen’s Slope, STL decomposition (seasonal-trend using LOESS), and linear regression. Civil Engineering students work from shared GitHub repositories, where they explore, run, and interpret results using scaffolded Python notebooks. While most students are not expected to write code, they are able to understand and run the scripts provided, allowing them to focus on interpreting seasonal statistical outputs and drawing conclusions from environmental data. This gives them the ability to explore the theoretical landscape—varying time periods, catchments, or climate zones—and apply statistical reasoning to real-world engineering scenarios. The approach supports version control and peer interaction, while familiarising students with reproducible workflows and analytical thinking grounded in scientific evidence.

At the MSc level, I collaborate more directly with students on active machine learning problems. In one project currently underway, my student is developing a random forest framework to characterise the flow properties of geological materials using µCT (micro-computed tomography) image data. We work from a shared GitHub repository, where I can review, comment on, and edit her codebase while developing supplementary tools for pore-network modelling. These include TauFactor and PoreSpy in Python, as well as exploratory work integrating her results into C++ libraries such as Palabos. The shared coding environment supports real-time collaboration and asynchronous review, reinforcing best practices in model validation, documentation, and interdisciplinary exchange.

While I have previously scaled similar workflows more widely into MSc and BSc modules, I have since reduced their use after observing cognitive overload among some less-experienced cohorts. This adjustment ensures that the collaborative technologies I deploy remain pedagogically effective and proportionate to students’ readiness.

***Core Area 4 Case ii: Evidence***

<a href="/assets/img/GitHub.png" target="_blank" style="text-decoration: underline; color: #004080;">-(Evidence 1) MSc Project Collaborative GitHub Repository</a>

<a href="/assets/img/representativecode.jpg" target="_blank" style="text-decoration: underline; color: #004080;">-(Evidence 2) Representative Code Sample With Markup Indicating Corrections</a>


<a href="/assets/img/CollabCodeEmail.pdf" target="_blank" style="text-decoration: underline; color: #004080;">-(Evidence 3) Representative Collaborative Coding Email Exhcange</a>


***Core Area 4 Reflections***

What I’ve learned across these collaborations is that technical expertise alone does not guarantee successful outcomes. Progress hinges on interpretability, shared understanding, and the ability to build trust across disciplinary divides. My role in the DSG challenges has shifted from technical contributor to translator: someone who frames problems clearly, holds the technical and environmental threads together, and ensures teams stay grounded in the real-world stakes of their work. That shift has deepened my appreciation for facilitation as a scholarly act, not merely logistical or interpersonal, but intellectual.

The work with students via GitHub has sharpened this further. Collaborative coding can empower students, but only if the scaffolding is well matched to their readiness. I’ve learned not to mistake exposure for comprehension. Earlier in my practice, I extended notebook-based workflows too widely, assuming that accessibility would translate into understanding. It did not. Some students became overwhelmed; others disengaged. That feedback prompted a shift. I now use these tools more selectively, ensuring they support conceptual development rather than hinder it. The technology enables collaboration, but its effectiveness depends on proportion and purpose.

In both academic and professional settings, I have come to value coordination over control, and clarity over complexity. Whether supervising MSc projects or facilitating research sprints, the most productive outcomes have come not from technical brilliance, but from narrowing scope, defining terms, and fostering mutual respect. Working with others is not simply a professional expectation; it is the condition under which better ideas emerge.




