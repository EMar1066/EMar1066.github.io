---
layout: post
title: "Core Area 4: Communication - Working With Others"
author: "Eric Martin"
date: 2025-07-27
categories: documentation
image: DSGbw.jpg
---
<p style="font-size: 1.75em; font-weight: bold; text-align: center;">
<em>“The effects of technology do not occur at the level of opinions or concepts, but alter sense ratios or patterns of perception steadily and without any resistance.” </em>
</p>

<p style="text-align: right; font-size: 1.25em;">
<em>— Marshall McLuhan</em>
</p>



**Core Area 4 - Case i: Facilitating Cross-Disciplinary Collaboration in The Alan Turing Institute Data Study Groups**

The Data Study Group (DSG) is a flagship educational initiative run by The Alan Turing Institute, the UK’s national institute for data science and AI. Delivered as an intensive, collaborative forum, it brings together early-career researchers, doctoral students, and data scientists to tackle real-world problems posed by external partners. The programme complements the Institute’s doctoral and postdoctoral training and fellowship initiatives. While solutions are developed under time constraints, the broader aim is educational: to train future data scientists through applied, interdisciplinary problem-solving in an open, team-based setting.

The September 2024 project, <a href="https://www.turing.ac.uk/news/publications/data-study-group-final-report-british-geological-survey">Identifying Potential for Carbon Capture and Storage in Rock</a>, delivered in person through the Alan Turing Institute’s Data Study Group in partnership with the British Geological Survey (BGS), developed a modular machine learning pipeline for automated analysis of petrographic thin-section images, supporting early-stage CCS and hydrogen storage site selection. The team explored porosity estimation using pixel-level colour filtering, grain segmentation via watershed algorithms, and mineral classification with both feature-based random forests and U-Net convolutional networks. As facilitator, I contributed to project design, research direction, codebase development, and implementation strategy. I mentored and worked closely with postgraduate and postdoctoral researchers from across the UK and Europe, supporting technical decisions, bridging disciplinary gaps, guiding technical communication, and maintaining focus during an intensive, collaborative sprint. The challenge addressed a national need for scalable and reproducible assessment of archived geological samples, with over 500,000 thin sections at BGS alone, moving beyond manual and subjective workflows.

The January 2025 project,  <a href="https://www.turing.ac.uk/news/publications/data-study-group-final-report-british-geological-survey-0">Detecting Shallow Gas from Marine Seismic Images</a>, also in partnership with the British Geological Survey (BGS), was delivered online over a two-week period. It focused on automating the interpretation of legacy seismic scan data for shallow gas detection. The challenge addressed the digitisation and analysis of kilometres of deteriorated paper records using structure-preserving image enhancement, OCR-based shotpoint detection, and multi-stage deep learning pipelines for feature segmentation. The overarching objective was to use modern technological tools to extract actionable insights and improve the interpretation of a sizable legacy dataset. I served as co-facilitator, leading the design of the image enhancement pipeline, supporting the object detection architecture, and contributing to the theoretical framework and report delivery. I worked alongside postgraduate and postdoctoral researchers across institutions and time zones, supporting both the technical direction and collaborative team coordination. A follow-on phase is currently under consideration to integrate the OCR and segmentation modules into a deployable national screening tool for shallow gas hazard mitigation.

I am currently serving as Principal Investigator for the September 2025 Data Study Group challenge in partnership with Cefas (Centre for Environment, Fisheries and Aquaculture Science), focusing on oil leak detection from shipwrecks using sequential Synthetic Aperture Radar (SAR) imagery. My responsibilities in this role are at a higher level and include challenge design, literature synthesis, coordination with the Cefas data team, and alignment of technical aims with stakeholder priorities across The Alan Turing Institute, Cefas, and participating doctoral and postdoctoral researchers. The project addresses a key gap in environmental monitoring: the absence of time-aware SAR segmentation methods. Our aim is to integrate temporal models (e.g. Baysean methods, ConvLSTM, transformer-based architectures) with environmental priors such as wind vectors and spill-source proximity.

I lead the collaborative framing process, working closely with IP Owners, Facilitators, and Turing programme staff to define the challenge, manage deployment logistics, and finalise deliverables. The objective is to ensure the project supports both research innovation and policy-relevant outcomes. The event is currently in the pre-sprint phase, with delivery scheduled for Autumn 2025.

***Reflection***

***Evidence***

***References***


**Core Area 4 - Case ii: GitHub Repositories and Open Knowledge: Supporting Technical Collaboration in Higher Education**

I have worked extensively with students and colleagues on collaborative, code-based teaching and supervision. At the BSc level, I introduce students to noisy, seasonal time-series datasets and support their use of statistical methods including Mann–Kendall trend analysis, Sen’s Slope, STL decomposition (seasonal-trend using LOESS), and linear regression. Civil Engineering students work from shared GitHub repositories, where they explore, run, and interpret results using scaffolded Python notebooks. While most students are not expected to write code, they are able to understand and run the scripts provided, allowing them to focus on interpreting seasonal statistical outputs and drawing conclusions from environmental data. This gives them the ability to explore the theoretical landscape—varying time periods, catchments, or climate zones—and apply statistical reasoning to real-world engineering scenarios. The approach supports version control and peer interaction, while familiarising students with reproducible workflows and analytical thinking grounded in scientific evidence.

At the MSc level, I collaborate more directly with students on active machine learning problems. In one project currently underway, my student is developing a random forest framework to characterise the flow properties of geological materials using µCT (micro-computed tomography) image data. We work from a shared GitHub repository, where I can review, comment on, and edit her codebase while developing supplementary tools for pore-network modelling. These include TauFactor and PoreSpy in Python, as well as exploratory work integrating her results into C++ libraries such as Palabos. The shared coding environment supports real-time collaboration and asynchronous review, reinforcing best practices in model validation, documentation, and interdisciplinary exchange.

While I have previously scaled similar workflows more widely into MSc and BSc modules, I have since reduced their use after observing cognitive overload among some less-experienced cohorts. This adjustment ensures that the collaborative technologies I deploy remain pedagogically effective and proportionate to students’ readiness.



EVIDENCE, CODE SNIPPETS - CHAT LOGS, REPOSITORY SCREENSHOT

***Reflection***

***Evidence***

***References***
